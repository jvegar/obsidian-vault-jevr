# Chapter 8: ECS Task Definition

Welcome to the final chapter! In [Chapter 7: Configuration Management](07_configuration_management_.md), we saw how our application loads settings like database URLs and Kafka addresses, often relying on environment variables injected during deployment. We even saw snippets of configuration files (`task-def-production.json`, `task-def-staging.json`) used for this injection.

But what *is* that file? How does the cloud platform (AWS) know *which* code to run, how much computing power to give it, and exactly how to pass in those settings from Chapter 7? That's the job of the **ECS Task Definition**.

## What's the Goal? The Instruction Manual for AWS

Imagine you've built your application (`assignment.cmd.api`), tested it, and packaged it up (using Docker, which we'll touch on). Now you want to run it in the cloud using AWS's Elastic Container Service (ECS).

How do you tell ECS exactly how to run your specific application? You need to provide instructions:

*   Which packaged version of your application (Docker image) should it use?
*   How much CPU and memory does this application need to run properly?
*   What environment variables (like `NODE_ENV=production`) should be set?
*   Are there any secret passwords or API keys (like the database URL or Kafka addresses from Chapter 7) that need to be securely given to the application?
*   Where should the application send its logs so you can see them later?

The **ECS Task Definition** is the answer. Think of it as a detailed **instruction manual** or **blueprint** written in a specific format (JSON) that you give to AWS ECS. ECS reads this manual and follows it precisely to launch and manage your application container.

## Key Concepts: Building the Blueprint

Let's break down the main parts of this instruction manual:

1.  **What it is:** A JSON file that describes *how* to run one or more containers as a single unit (a "Task") in AWS ECS.
2.  **Docker Image:** Specifies the exact packaged version of your application code. This points to a container image stored in a registry (like AWS Elastic Container Registry - ECR). This image is created using instructions from a file called `Dockerfile` in our project.
3.  **Resources (CPU/Memory):** Defines how much processing power (CPU units) and memory (MB or GB) AWS should reserve for your application task. This ensures it has enough resources to run without interfering with other applications.
4.  **Environment Variables:** Allows you to set non-sensitive configuration values directly, like setting `NODE_ENV` to `production` or `staging`. The application can read these just like we saw in [Chapter 7: Configuration Management](07_configuration_management_.md).
5.  **Secrets:** Provides a *secure* way to inject sensitive configuration values (like database passwords, API keys, Kafka broker URLs stored in AWS Systems Manager Parameter Store or AWS Secrets Manager) into the application as environment variables. This avoids hardcoding secrets in the task definition itself.
6.  **Logging Configuration:** Tells ECS how to handle the logs generated by your application. Typically, this is configured to send logs to AWS CloudWatch Logs for easy viewing and monitoring.
7.  **Networking:** Defines network settings, like which ports the container needs to expose (e.g., port 3007 for our web server) and how it connects to the network (e.g., using `awsvpc` mode for detailed network control).

## How It Works: From Blueprint to Running Application

1.  **Define:** You create the Task Definition JSON file (`task-def-production.json` or `task-def-staging.json`).
2.  **Register:** You register this definition with AWS ECS. It gets stored and usually receives a version number (e.g., `my-app-task:1`, `my-app-task:2`).
3.  **Run Task/Service:** You tell ECS to run a "Task" or create a "Service" (which manages multiple copies of a Task) using a specific registered Task Definition version.
4.  **ECS Executes:** ECS reads the specified Task Definition and performs the following actions:
    *   Finds the required AWS infrastructure (like servers or Fargate capacity).
    *   Pulls the specified Docker image from the container registry (ECR).
    *   Allocates the defined CPU and memory.
    *   Sets up the network according to the definition.
    *   Injects the environment variables and secrets from Parameter Store.
    *   Starts your application container using the command specified (often in the `Dockerfile`).
    *   Configures log routing to send application output to CloudWatch.

Essentially, the Task Definition translates your requirements into concrete actions performed by AWS ECS.

## Looking at the Blueprint: The Task Definition File

Let's examine parts of the `task-def-production.json` file provided earlier. This is the instruction manual for our `assignment.cmd.api` in the production environment.

*(Note: JSON is structured with keys and values, like `"key": "value"`. Braces `{}` define objects, and square brackets `[]` define lists/arrays.)*

**1. Basic Information:**

```json
{
  "family": "haul-assignment-cmd-api-production", // Name for this group of task defs
  "networkMode": "awsvpc", // Specific AWS networking mode
  "requiresCompatibilities": ["FARGATE"], // Runs on AWS Fargate (serverless)
  "executionRoleArn": "arn:aws:iam::...:role/ecsTaskExecutionRole", // Permissions for ECS
  "memory": "4096", // Total Memory for the task (4GB)
  "cpu": "1024" // Total CPU units for the task (1 vCPU)
  // ... other top-level settings ...
}
```

*   **Explanation:**
    *   `family`: A name for this application's task definitions.
    *   `networkMode`, `requiresCompatibilities`: Defines technical requirements, here indicating it runs on AWS Fargate using `awsvpc` networking.
    *   `executionRoleArn`: Specifies an AWS role that grants ECS permission to do things like pull the Docker image from ECR and fetch secrets from SSM Parameter Store.
    *   `memory`, `cpu`: Sets the *total* resources requested for the entire task when running on Fargate.

**2. Container Definition (The Core Instructions):**

The `containerDefinitions` array lists the containers to run. In our case, there's usually just one for the application itself.

```json
  // ... inside the main JSON object ...
  "containerDefinitions": [
    {
      "name": "haul-assignment-cmd-api-production", // A name for this specific container
      "image": "333759594765.dkr.ecr.us-west-2.amazonaws.com/haul-assignment-cmd-api-production", // The Docker image!
      "essential": true, // If this container fails, the whole task fails
      "portMappings": [ // Network ports
        {
          "containerPort": 3007, // The port the app listens on inside the container
          "protocol": "tcp"
          // hostPort might be omitted in awsvpc mode
        }
      ],
      // ... more container settings below ...
    }
  ]
  // ...
```

*   **Explanation:**
    *   `name`: A simple name for the container within the task.
    *   `image`: **Crucial!** This tells ECS exactly which Docker image to pull and run. It points to our application image stored in AWS ECR (Elastic Container Registry).
    *   `essential`: Marks this container as critical for the task.
    *   `portMappings`: Opens port 3007 inside the container so it can receive traffic (like health checks or API calls, though our `cmd.api` mostly uses Kafka).

**3. Logging Configuration:**

How does ECS handle the application's console output (logs)?

```json
      // ... inside the container definition ...
      "logConfiguration": {
        "logDriver": "awslogs", // Use the AWS CloudWatch Logs driver
        "options": {
          "awslogs-group": "/ecs/haul-assignment-cmd-api-production", // Log group name in CloudWatch
          "awslogs-region": "us-west-2", // AWS region for the logs
          "awslogs-stream-prefix": "ecs" // Prefix for log stream names
        }
      },
      // ... more settings ...
```

*   **Explanation:** This section configures ECS to capture the container's logs and send them to AWS CloudWatch Logs, organized into the specified log group. This is essential for monitoring and debugging.

**4. Environment Variables & Secrets:**

How do we pass configuration from [Chapter 7: Configuration Management](07_configuration_management_.md) into the container?

```json
      // ... inside the container definition ...
      "environment": [ // Regular environment variables
        {
          "name": "NODE_ENV",
          "value": "production" // Set NODE_ENV for the production environment
        }
      ],
      "secrets": [ // Securely injected secrets
        {
          "name": "ASSIGNMENT_EVENT_STORE_URL_PRODUCTION", // The env var name inside the container
          "valueFrom": "arn:aws:ssm:us-west-2:333759594765:parameter/ASSIGNMENT_EVENT_STORE_URL_PRODUCTION" // ARN of the secret in SSM Parameter Store
        },
        {
          "name": "PRODUCTION_KAFKA_NODE_1",
          "valueFrom": "arn:aws:ssm:us-west-2:333759594765:parameter/PRODUCTION_KAFKA_NODE_1"
        }
        // ... more secrets listed (API keys, other Kafka nodes, Redis etc.)
      ]
      // ...
```

*   **Explanation:**
    *   `environment`: Defines standard, non-sensitive environment variables. Here, `NODE_ENV` is set to `production`, which our config loader in Chapter 7 uses to load `production.ts`.
    *   `secrets`: This is the secure way to handle sensitive data. For each entry:
        *   `name`: Specifies the name of the environment variable that will be available *inside* the running container (e.g., `ASSIGNMENT_EVENT_STORE_URL_PRODUCTION`).
        *   `valueFrom`: Provides the Amazon Resource Name (ARN) of the parameter stored securely in AWS Systems Manager (SSM) Parameter Store. ECS fetches this value from SSM and injects it into the container environment *without* exposing it in the Task Definition file itself. Our `production.ts` config file then reads these environment variables using `process.env`.

## The Dockerfile: Packaging the Application

Where does the `image` mentioned in the Task Definition come from? It's built using instructions in a `Dockerfile`. Here's a simplified view of our `Dockerfile`:

```dockerfile
# Use an official Node.js runtime as a parent image
FROM node:12.13.1 as dist
WORKDIR /tmp/
COPY . . # Copy source code
RUN npm install # Install dependencies
RUN npm run build # Build the application (compile TS to JS)

# ... (stage for copying only production node_modules) ...

# Final stage - smaller image
FROM node:12.13.1
WORKDIR /usr/src/app
COPY --from=node_modules /tmp/node_modules ./node_modules # Copy production deps
COPY --from=dist /tmp/dist ./dist # Copy built application code
EXPOSE 3007 # Inform Docker the container listens on port 3007

# Command to run when the container starts
CMD ["node", "dist/main.js"]
```

*   **Explanation:**
    *   This file defines steps to package our application.
    *   It starts from a base Node.js image.
    *   It copies the source code, installs dependencies, and builds the project (creating the `dist` folder).
    *   It copies the necessary built files (`dist`) and production dependencies (`node_modules`) into a clean final image.
    *   `EXPOSE 3007` documents the port used (also specified in the Task Definition).
    *   `CMD ["node", "dist/main.js"]` specifies the default command to run when the container starts â€“ it executes our compiled application entry point (`main.js`).

This `Dockerfile` is used by a build process (often in a CI/CD pipeline) to create the Docker image, which is then pushed to the AWS ECR repository, ready for the Task Definition to reference it.

## Conclusion

You've now learned about the **ECS Task Definition**!

*   It's the essential **JSON blueprint** or **instruction manual** that tells AWS ECS exactly how to run our `assignment.cmd.api` application.
*   It specifies the **Docker image** (built from the `Dockerfile`) to use.
*   It defines required **CPU** and **Memory** resources.
*   It sets up **logging** to CloudWatch.
*   It configures **networking** (like ports).
*   Crucially, it injects configuration using **environment variables** for regular settings and **secrets** (pulled securely from AWS SSM) for sensitive data, bridging the gap with our [Chapter 7: Configuration Management](07_configuration_management_.md).

Understanding the Task Definition helps you see how the application code, its dependencies, configuration, and operational requirements all come together when deploying to the cloud. This concludes our tour through the key concepts of the `assignment.cmd.api` project!

---

Generated by [AI Codebase Knowledge Builder](https://github.com/The-Pocket/Tutorial-Codebase-Knowledge)